{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c3886c7-656b-4159-9190-1a286d3eece4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.applications import VGG16 \n",
    "from tensorflow.keras.models import Sequential \n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout \n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.datasets import cifar10 \n",
    "from tensorflow.keras.utils import plot_model \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f6df68e-a96e-49ff-bc24-0ace53c51c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10 \n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data() \n",
    "x_train = x_train / 255.0 \n",
    "x_test = x_test / 255.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb764ea2-b218-40ca-b409-d0209b12a84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- [Errno 11001] getaddrinfo failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mgaierror\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1319\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1319\u001b[0m     h\u001b[38;5;241m.\u001b[39mrequest(req\u001b[38;5;241m.\u001b[39mget_method(), req\u001b[38;5;241m.\u001b[39mselector, req\u001b[38;5;241m.\u001b[39mdata, headers,\n\u001b[0;32m   1320\u001b[0m               encode_chunked\u001b[38;5;241m=\u001b[39mreq\u001b[38;5;241m.\u001b[39mhas_header(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTransfer-encoding\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1338\u001b[0m, in \u001b[0;36mHTTPConnection.request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1337\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Send a complete request to the server.\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_request(method, url, body, headers, encode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1384\u001b[0m, in \u001b[0;36mHTTPConnection._send_request\u001b[1;34m(self, method, url, body, headers, encode_chunked)\u001b[0m\n\u001b[0;32m   1383\u001b[0m     body \u001b[38;5;241m=\u001b[39m _encode(body, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbody\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m-> 1384\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mendheaders(body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1333\u001b[0m, in \u001b[0;36mHTTPConnection.endheaders\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1332\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CannotSendHeader()\n\u001b[1;32m-> 1333\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_send_output(message_body, encode_chunked\u001b[38;5;241m=\u001b[39mencode_chunked)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1093\u001b[0m, in \u001b[0;36mHTTPConnection._send_output\u001b[1;34m(self, message_body, encode_chunked)\u001b[0m\n\u001b[0;32m   1092\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer[:]\n\u001b[1;32m-> 1093\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msend(msg)\n\u001b[0;32m   1095\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m message_body \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1096\u001b[0m \n\u001b[0;32m   1097\u001b[0m     \u001b[38;5;66;03m# create a consistent interface to message_body\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1037\u001b[0m, in \u001b[0;36mHTTPConnection.send\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_open:\n\u001b[1;32m-> 1037\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1038\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1472\u001b[0m, in \u001b[0;36mHTTPSConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1470\u001b[0m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnect to a host on a given (SSL) port.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1472\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mconnect()\n\u001b[0;32m   1474\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tunnel_host:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\http\\client.py:1003\u001b[0m, in \u001b[0;36mHTTPConnection.connect\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1002\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttp.client.connect\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport)\n\u001b[1;32m-> 1003\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msock \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_connection(\n\u001b[0;32m   1004\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost,\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mport), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msource_address)\n\u001b[0;32m   1005\u001b[0m \u001b[38;5;66;03m# Might fail in OSs that don't implement TCP_NODELAY\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:840\u001b[0m, in \u001b[0;36mcreate_connection\u001b[1;34m(address, timeout, source_address, all_errors)\u001b[0m\n\u001b[0;32m    839\u001b[0m exceptions \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 840\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m getaddrinfo(host, port, \u001b[38;5;241m0\u001b[39m, SOCK_STREAM):\n\u001b[0;32m    841\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\socket.py:977\u001b[0m, in \u001b[0;36mgetaddrinfo\u001b[1;34m(host, port, family, type, proto, flags)\u001b[0m\n\u001b[0;32m    976\u001b[0m addrlist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m--> 977\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m _socket\u001b[38;5;241m.\u001b[39mgetaddrinfo(host, port, family, \u001b[38;5;28mtype\u001b[39m, proto, flags):\n\u001b[0;32m    978\u001b[0m     af, socktype, proto, canonname, sa \u001b[38;5;241m=\u001b[39m res\n",
      "\u001b[1;31mgaierror\u001b[0m: [Errno 11001] getaddrinfo failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:311\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[0m\n\u001b[0;32m    310\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 311\u001b[0m     urlretrieve(origin, download_target, DLProgbar())\n\u001b[0;32m    312\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mHTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:214\u001b[0m, in \u001b[0;36murlretrieve\u001b[1;34m(url, filename, reporthook, data)\u001b[0m\n\u001b[0;32m    212\u001b[0m url_type, path \u001b[38;5;241m=\u001b[39m _splittype(url)\n\u001b[1;32m--> 214\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mclosing(urlopen(url, data)) \u001b[38;5;28;01mas\u001b[39;00m fp:\n\u001b[0;32m    215\u001b[0m     headers \u001b[38;5;241m=\u001b[39m fp\u001b[38;5;241m.\u001b[39minfo()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:189\u001b[0m, in \u001b[0;36murlopen\u001b[1;34m(url, data, timeout, context)\u001b[0m\n\u001b[0;32m    188\u001b[0m     opener \u001b[38;5;241m=\u001b[39m _opener\n\u001b[1;32m--> 189\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opener\u001b[38;5;241m.\u001b[39mopen(url, data, timeout)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:489\u001b[0m, in \u001b[0;36mOpenerDirector.open\u001b[1;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[0;32m    488\u001b[0m sys\u001b[38;5;241m.\u001b[39maudit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124murllib.Request\u001b[39m\u001b[38;5;124m'\u001b[39m, req\u001b[38;5;241m.\u001b[39mfull_url, req\u001b[38;5;241m.\u001b[39mdata, req\u001b[38;5;241m.\u001b[39mheaders, req\u001b[38;5;241m.\u001b[39mget_method())\n\u001b[1;32m--> 489\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_open(req, data)\n\u001b[0;32m    491\u001b[0m \u001b[38;5;66;03m# post-process response\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:506\u001b[0m, in \u001b[0;36mOpenerDirector._open\u001b[1;34m(self, req, data)\u001b[0m\n\u001b[0;32m    505\u001b[0m protocol \u001b[38;5;241m=\u001b[39m req\u001b[38;5;241m.\u001b[39mtype\n\u001b[1;32m--> 506\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_chain(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_open, protocol, protocol \u001b[38;5;241m+\u001b[39m\n\u001b[0;32m    507\u001b[0m                           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_open\u001b[39m\u001b[38;5;124m'\u001b[39m, req)\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:466\u001b[0m, in \u001b[0;36mOpenerDirector._call_chain\u001b[1;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[0;32m    465\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(handler, meth_name)\n\u001b[1;32m--> 466\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    467\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1367\u001b[0m, in \u001b[0;36mHTTPSHandler.https_open\u001b[1;34m(self, req)\u001b[0m\n\u001b[0;32m   1366\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mhttps_open\u001b[39m(\u001b[38;5;28mself\u001b[39m, req):\n\u001b[1;32m-> 1367\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdo_open(http\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mHTTPSConnection, req,\n\u001b[0;32m   1368\u001b[0m                         context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_context)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\urllib\\request.py:1322\u001b[0m, in \u001b[0;36mAbstractHTTPHandler.do_open\u001b[1;34m(self, http_class, req, **http_conn_args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err: \u001b[38;5;66;03m# timeout error\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m URLError(err)\n\u001b[0;32m   1323\u001b[0m r \u001b[38;5;241m=\u001b[39m h\u001b[38;5;241m.\u001b[39mgetresponse()\n",
      "\u001b[1;31mURLError\u001b[0m: <urlopen error [Errno 11001] getaddrinfo failed>",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m vgg_base \u001b[38;5;241m=\u001b[39m VGG16(weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimagenet\u001b[39m\u001b[38;5;124m'\u001b[39m, include_top\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, input_shape\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m32\u001b[39m, \u001b[38;5;241m3\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\applications\\vgg16.py:218\u001b[0m, in \u001b[0;36mVGG16\u001b[1;34m(include_top, weights, input_tensor, input_shape, pooling, classes, classifier_activation, name)\u001b[0m\n\u001b[0;32m    211\u001b[0m         weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[0;32m    212\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg16_weights_tf_dim_ordering_tf_kernels.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    213\u001b[0m             WEIGHTS_PATH,\n\u001b[0;32m    214\u001b[0m             cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    215\u001b[0m             file_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m64373286793e3c8b2b4e3219cbf3544b\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    216\u001b[0m         )\n\u001b[0;32m    217\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 218\u001b[0m         weights_path \u001b[38;5;241m=\u001b[39m file_utils\u001b[38;5;241m.\u001b[39mget_file(\n\u001b[0;32m    219\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    220\u001b[0m             WEIGHTS_PATH_NO_TOP,\n\u001b[0;32m    221\u001b[0m             cache_subdir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    222\u001b[0m             file_hash\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m6d6bbae143d832006294945121d1f1fc\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    223\u001b[0m         )\n\u001b[0;32m    224\u001b[0m     model\u001b[38;5;241m.\u001b[39mload_weights(weights_path)\n\u001b[0;32m    225\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m weights \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\file_utils.py:315\u001b[0m, in \u001b[0;36mget_file\u001b[1;34m(fname, origin, untar, md5_hash, file_hash, cache_subdir, hash_algorithm, extract, archive_format, cache_dir, force_download)\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39mcode, e\u001b[38;5;241m.\u001b[39mmsg))\n\u001b[0;32m    314\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m urllib\u001b[38;5;241m.\u001b[39merror\u001b[38;5;241m.\u001b[39mURLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m--> 315\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(error_msg\u001b[38;5;241m.\u001b[39mformat(origin, e\u001b[38;5;241m.\u001b[39merrno, e\u001b[38;5;241m.\u001b[39mreason))\n\u001b[0;32m    316\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mException\u001b[39;00m, \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m):\n\u001b[0;32m    317\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(download_target):\n",
      "\u001b[1;31mException\u001b[0m: URL fetch failure on https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5: None -- [Errno 11001] getaddrinfo failed"
     ]
    }
   ],
   "source": [
    "vgg_base = VGG16(weights='imagenet', include_top=False, input_shape=(32, 32, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7b603e-b64d-46e1-b1a8-cb44e8ee670f",
   "metadata": {},
   "outputs": [],
   "source": [
    " for layer in vgg_base.layers: \n",
    "    layer.trainable = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0726a696-36cb-4d77-8748-a433e44acb84",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential() \n",
    "model.add(vgg_base) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(512, activation='relu')) \n",
    "model.add(Dropout(0.5)) \n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1deb7f0-9995-42a5-8c77-8fd445a62adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(learning_rate=0.0001), \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15fae5cd-4b60-4d01-bcc1-0c7738116592",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='cnn.png', show_shapes=True, \n",
    "           show_layer_names=True, dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffb2001-b93b-4bc8-9160-540204a10533",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(20, 20)) \n",
    "img = plt.imread('cnn.png') \n",
    "plt.imshow(img) \n",
    "plt.axis('off') \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c36a88-f731-4f55-b523-50ce9bb68ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# MNIST images are grayscale (28x28), expand dims to make them 3-channel\n",
    "x_train = x_train[..., None]  # shape: (60000, 28, 28, 1)\n",
    "x_test = x_test[..., None]\n",
    "\n",
    "# Normalize to [0,1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e96843-98a0-42d8-aaf9-03c010b7004e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize to [0,1]\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfd10de-9ce7-4d58-8429-e04290b3055c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "\n",
    "# Load CIFAR-10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "\n",
    "def preprocess(img, label):\n",
    "    img = tf.cast(img, tf.float32) / 255.0   # normalize lazily\n",
    "    img = tf.image.resize(img, (64,64))      # smaller size than 224x224\n",
    "    return img, label\n",
    "\n",
    "# Build datasets\n",
    "train_ds = tf.data.Dataset.from_tensor_slices((x_train, y_train))\n",
    "train_ds = train_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "test_ds = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_ds = test_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7b6a53-0890-4cbc-b1e8-c26d2228ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_small = x_train[:5000]\n",
    "y_train_small = y_train[:5000]\n",
    "x_test_small = x_test[:1000]\n",
    "y_test_small = y_test[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a16e3b17-09d0-44bc-a4fb-4a3a597b3985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "model = models.Sequential([\n",
    "    layers.Input(shape=(32, 32, 3)),   # ðŸ‘ˆ define input here\n",
    "    layers.Conv2D(32, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.MaxPooling2D((2,2)),\n",
    "    layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(10, activation='softmax')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a6589e-5998-454e-9de6-80bb7d191f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Expand dims -> (28,28,1)\n",
    "x_train = np.expand_dims(x_train, -1)  \n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "# Convert to 3 channels -> (28,28,3)\n",
    "x_train = np.repeat(x_train, 3, axis=-1)\n",
    "x_test = np.repeat(x_test, 3, axis=-1)\n",
    "\n",
    "# Normalize to [0,1]\n",
    "x_train = x_train.astype(\"float32\") / 255.0\n",
    "x_test = x_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "num_classes = 10\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "# Build CNN model\n",
    "model = models.Sequential([\n",
    "    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 3)),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.MaxPooling2D((2, 2)),\n",
    "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(\"Test accuracy:\", test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda8690a-6c66-491d-924d-b726b3a95d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_acc = model.evaluate(x_test, y_test) \n",
    "print(f'Test Loss: {test_loss:.4f}') \n",
    "print(f'Test Accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f4df02-3318-473b-99b6-1dadab69b058",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b0f456-81b3-4291-be03-da31ed92deb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    " plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Example: plot training vs validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511e928a-96a3-4188-9247-c46790bca0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 1) \n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy') \n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy') \n",
    "plt.title('Model Accuracy') \n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Accuracy') \n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d791454e-1ee3-4fe3-a687-b70be196b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(1, 2, 2) \n",
    "plt.plot(history.history['loss'], label='Train Loss') \n",
    "plt.plot(history.history['val_loss'], label='Validation Loss') \n",
    "plt.title('Model Loss') \n",
    "plt.xlabel('Epoch') \n",
    "plt.ylabel('Loss') \n",
    "plt.legend() \n",
    "plt.tight_layout() \n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1db7058-b268-48b1-934e-0d9e97ace6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer', \n",
    "'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d38a5a1-bbe6-43ca-9e20-5de056ed014c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "# Resize from 32x32x3 to 28x28x3\n",
    "sample = tf.image.resize(x_test[0], (28, 28))  # shape (28,28,3)\n",
    "sample = np.expand_dims(sample, axis=0)        # shape (1,28,28,3)\n",
    "\n",
    "# Predict\n",
    "prediction = model.predict(sample)\n",
    "predicted_class = np.argmax(prediction)\n",
    "\n",
    "print(\"Predicted class:\", class_names[predicted_class])\n",
    "\n",
    "# Plot\n",
    "plt.imshow(x_test[0])  # original image\n",
    "plt.title(f\"Predicted: {class_names[predicted_class]}\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30cb546-21f9-4d47-bfa3-00568795a8dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
